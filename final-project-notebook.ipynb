{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Final Project - Synthetic Image Generation\n\n## Problem Statement\n\nGenerate common skin rashes based on textual commands varying the following three factors:\n- Skin rash type (e.g., eczema, ringworm, dermatitis)\n- Skin color (e.g., fair, brown, black)\n- Affected area (e.g., chest, neck, hand)\n\nAn example command will be like \"generate a few images of a ringworm type of rash at the back of the neck area on a fair skin\". Build an interface and a deep generative model to process such queries and visualize the output. Please deal with 3-4 rash types that you are not uncomfortable to look at.\n\nHint: Explore using latent diffusion model, fine-tuning its CLIP model component. Make sure to collect some training images from the internet.\n\nThis is a group project, so you will collaborate with another student. You are going to present on Wednesday, the 24th between noon-3pm. Please prepare about a dozen slides. This is your final, so want a robust approach and an implementation.\n\nProf. Das\n\n## Approach Explanation\n","metadata":{}},{"cell_type":"markdown","source":"To approach the problem of synthetic image generation for common skin rashes, we've implemented a solution using PyTorch and Streamlit. Here's an overview of our approach:\n\n1. **Data Preprocessing and Model Selection**:\n   - We load necessary libraries and models, including CLIP (Contrastive Language-Image Pre-training) for text encoding, a Variational Autoencoder (VAE) for image generation, and a U-Net model for diffusion process.\n\n2. **Interface Design**:\n   - Utilizing Streamlit, we create an intuitive interface for users to input their preferences for generating skin rash images. Users can select the type of skin rash, skin color, and affected area through dropdown menus.\n\n3. **Image Generation**:\n   - Upon clicking the \"Generate Images\" button, the selected preferences are translated into a textual command.\n   - We employ a diffusion process to convert the textual prompt into images. This process involves multiple steps, during which the latent representations of images are iteratively adjusted to match the provided prompt.\n   - Progress is displayed using a progress bar to keep users informed about the generation process.\n\n4. **Results Presentation**:\n   - Throughout the generation process, interim images are displayed to the user to provide real-time feedback.\n   - Once the generation is complete, the final image(s) are displayed along with the detailed description of the prompt for which it was generated.\n\n5. **Future Enhancements**:\n   - We aim to further optimize the generation process for better efficiency and quality.\n   - Additionally, we plan to incorporate more diverse skin rash types and expand the range of affected areas and skin colors for increased flexibility.\n","metadata":{}},{"cell_type":"code","source":"!pip install diffusers","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:48:35.274638Z","iopub.execute_input":"2024-04-22T21:48:35.275696Z","iopub.status.idle":"2024-04-22T21:48:47.600446Z","shell.execute_reply.started":"2024-04-22T21:48:35.275643Z","shell.execute_reply":"2024-04-22T21:48:47.599297Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: diffusers in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (6.11.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.22.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (9.5.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.9.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.2.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.2->diffusers) (3.1.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install streamlit\n!npm install localtunnel","metadata":{"execution":{"iopub.status.busy":"2024-04-22T21:48:47.602585Z","iopub.execute_input":"2024-04-22T21:48:47.602896Z","iopub.status.idle":"2024-04-22T21:49:02.033827Z","shell.execute_reply.started":"2024-04-22T21:48:47.602867Z","shell.execute_reply":"2024-04-22T21:49:02.032855Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Requirement already satisfied: streamlit in /opt/conda/lib/python3.10/site-packages (1.33.0)\nRequirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.7.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.2.4)\nRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<2,>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=16.8 in /opt/conda/lib/python3.10/site-packages (from streamlit) (21.3)\nRequirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.1.4)\nRequirement already satisfied: pillow<11,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\nRequirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (15.0.2)\nRequirement already satisfied: requests<3,>=2.27 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.31.0)\nRequirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.7.0)\nRequirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\nRequirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.9.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.41)\nRequirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.8.1b0)\nRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\nRequirement already satisfied: watchdog>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.0.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25,>=16.8->streamlit) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.17.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.16.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n\u001b[K\u001b[?25hm#########\u001b[0m\u001b[100;90m.........\u001b[0m] \\ idealTree: \u001b[32;40mtiming\u001b[0m \u001b[35midealTree\u001b[0m Completed in 191ms\u001b[0m\u001b[K\nup to date, audited 23 packages in 726ms\n\n3 packages are looking for funding\n  run `npm fund` for details\n\n2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n\nTo address all issues (including breaking changes), run:\n  npm audit fix --force\n\nRun `npm audit` for details.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile app.py\nimport re\nimport torch, logging\n\nimport torch\nfrom PIL import Image\nimport io\n\n## disable warnings\nlogging.disable(logging.WARNING)  \n\n## Imaging  library\nfrom PIL import Image\nfrom torchvision import transforms as tfms\n\n## Basic libraries\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport shutil\nimport os\n\n## For video display\nfrom IPython.display import HTML\nfrom base64 import b64encode\n\n\n## Import the CLIP artifacts \nfrom transformers import CLIPTextModel, CLIPTokenizer\nfrom diffusers import AutoencoderKL, UNet2DConditionModel, LMSDiscreteScheduler\nfrom IPython.display import display, clear_output\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef extract_values(text):\n    # Regex patterns to extract skin color, rash type, and affected body part\n    colors = r\"(fair|dark|brown|black|white)\"\n    rash_types = r\"(eczema|ringworm|dermatitis)\"\n    body_parts = r\"(hand|chest|neck|face|leg|arm)\"\n    \n    # Search text for matches\n    color_match = re.search(colors, text, re.IGNORECASE)\n    rash_match = re.search(rash_types, text, re.IGNORECASE)\n    body_part_match = re.search(body_parts, text, re.IGNORECASE)\n    \n    # Extract matched values or use defaults\n    color = color_match.group(0) if color_match else 'fair'\n    rash_type = rash_match.group(0) if rash_match else 'eczema'\n    body_part = body_part_match.group(0) if body_part_match else 'hand'\n    \n    return color, rash_type, body_part\n\ndef magic_prompt(color, rash_type, body_part):\n    # Construct the detailed prompt using the extracted values\n    return f\"Create a highly detailed and realistic image showing the {body_part} of a person with {color} skin. The {body_part} should display a typical {rash_type} infection, characterized by a clearly visible rash.\"\n\n\n## Helper functions\ndef load_image(p):\n    '''\n    Function to load images from a defined path\n    '''\n    return Image.open(p).convert('RGB').resize((512,512))\n\ndef pil_to_latents(image):\n    '''\n    Function to convert image to latents\n    '''\n    init_image = tfms.ToTensor()(image).unsqueeze(0) * 2.0 - 1.0\n    init_image = init_image.to(device=\"cuda\", dtype=torch.float16) \n    init_latent_dist = vae.encode(init_image).latent_dist.sample() * 0.18215\n    return init_latent_dist\n\ndef latents_to_pil(latents):\n    '''\n    Function to convert latents to images\n    '''\n    latents = (1 / 0.18215) * latents\n    with torch.no_grad():\n        image = vae.decode(latents).sample\n    image = (image / 2 + 0.5).clamp(0, 1)\n    image = image.detach().cpu().permute(0, 2, 3, 1).numpy()\n    images = (image * 255).round().astype(\"uint8\")\n    pil_images = [Image.fromarray(image) for image in images]\n    return pil_images\n\n\ndef text_enc(prompts, maxlen=None):\n    '''\n    A function to take a texual promt and convert it into embeddings\n    '''\n    if maxlen is None: maxlen = tokenizer.model_max_length\n    inp = tokenizer(prompts, padding=\"max_length\", max_length=maxlen, truncation=True, return_tensors=\"pt\") \n    return text_encoder(inp.input_ids.to(\"cuda\"))[0].half()\n\ndef prompt_2_img(prompts, g=7.5, seed=100, steps=70, dim=512, save_int=True):\n    \"\"\"\n    Diffusion process to convert prompt to image, modified to yield images for Streamlit.\n    \"\"\"\n    \n    bs = len(prompts) \n    text = text_enc(prompts)\n    uncond = text_enc([\"\"] * bs, text.shape[1])\n    emb = torch.cat([uncond, text])\n    \n    if seed:\n        torch.manual_seed(seed)\n    \n    latents = torch.randn((bs, unet.in_channels, dim//8, dim//8))\n    scheduler.set_timesteps(steps)\n    latents = latents.to(\"cuda\").half() * scheduler.init_noise_sigma\n\n    for i, ts in enumerate(scheduler.timesteps):\n        inp = scheduler.scale_model_input(torch.cat([latents] * 2), ts)\n        with torch.no_grad():\n            u, t = unet(inp, ts, encoder_hidden_states=emb).sample.chunk(2)\n        pred = u + g*(t-u)\n        latents = scheduler.step(pred, ts, latents).prev_sample\n\n        if save_int and i % (steps // 70) == 0:  # Yield 10 images throughout the process\n            image = latents_to_pil(latents)[0]\n            buf = io.BytesIO()\n            image.save(buf, format=\"JPEG\")\n            byte_im = buf.getvalue()\n            yield byte_im  # Yield image in bytes format for Streamlit to display\n\n    final_image = latents_to_pil(latents)\n    final_buf = io.BytesIO()\n    final_image[0].save(final_buf, format=\"JPEG\")\n    final_byte_im = final_buf.getvalue()\n    yield final_byte_im  # Yield the final image\n\n## Initiating tokenizer and encoder.\ntokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16)\ntext_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\", torch_dtype=torch.float16).to(\"cuda\")\n\n## Initiating the VAE\nvae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", torch_dtype=torch.float16).to(\"cuda\")\n\n## Initializing a scheduler and Setting number of sampling steps\nscheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)\nscheduler.set_timesteps(50)\n\n## Initializing the U-Net model\nunet = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", torch_dtype=torch.float16).to(\"cuda\")\n\n\nimport streamlit as st\n\n# Custom CSS to inject for better control over the Streamlit layout\nst.markdown(\n    \"\"\"\n    <style>\n    .big-font {\n        font-size:20px !important;\n        font-weight: bold;\n    }\n    .image-gen {\n        padding-top: 10px;\n        padding-bottom: 30px;\n    }\n    </style>\n    \"\"\", unsafe_allow_html=True)\n\n# Title of the app\nst.title('🔬 Skin Rash Generator')\n\n# Welcome message with enhanced markdown\nst.markdown(\"\"\"\nWelcome to the Skin Rash Generator! Use the commands below to generate images of common skin rashes based on your preferences.\n\"\"\", unsafe_allow_html=True)\n\n# Assume other imports and function definitions (extract_values, magic_prompt) are already included as discussed\n\n# Text input for user description\ndescription_input = st.text_input('Describe the rash:', 'Type a detailed description of the skin rash including skin color, rash type, and affected area.', help='Enter details like skin color, type of rash, and body part affected.')\n\n# Button to trigger image generation\nif st.button('🖼️ Generate Images'):\n    image_placeholder = st.empty()\n    progress_bar = st.progress(0)\n\n    # Extract values from the user's description\n    color, rash_type, body_part = extract_values(description_input)\n    \n    st.write(\"Extracting values from the description. Replacing with default values if not found.\")\n    extracted_values = f\"Skin Color - {color}, Rash Type - {rash_type}, Body Part - {body_part}\"\n    st.write(\"Extracted values:\", extracted_values)\n    \n    # Generate detailed prompt based on extracted values\n    detailed_prompt = magic_prompt(color, rash_type, body_part)\n\n    generator_original = prompt_2_img([description_input], save_int=True)\n    generator_new = prompt_2_img([detailed_prompt], save_int=True)\n    total_steps = 70  # Total number of steps expected in the generation process\n\n    # Set up layout for images and progress bar\n    col1, col2 = st.columns(2)\n    with col1:\n        st.write(\"Original Image:\")\n        original_placeholder = st.empty()\n    with col2:\n        st.write(\"Enhanced Prompt Image:\")\n        new_placeholder = st.empty()\n        \n    for step, image_bytes in enumerate(generator_original):\n        with st.spinner('Generating images...'):\n            pg = min((step) / total_steps, 100)\n            progress_text = f\"Generating Image, Progress: {int(pg*100)}%\"\n            progress_bar.progress(pg, text=progress_text)\n            if step%13 == 0:\n                original_placeholder.image(image_bytes, use_column_width=True)\n\n    for step, image_bytes in enumerate(generator_new):\n        with st.spinner('Generating images with new prompt...'):\n            pg = min((step) / total_steps, 100)\n            progress_text = f\"Generating Image, Progress: {int(pg*100)}%\"\n            progress_bar.progress(pg, text=progress_text)\n            if step%13 == 0:\n                new_placeholder.image(image_bytes, use_column_width=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:55:59.018660Z","iopub.execute_input":"2024-04-22T23:55:59.018995Z","iopub.status.idle":"2024-04-22T23:55:59.031223Z","shell.execute_reply.started":"2024-04-22T23:55:59.018963Z","shell.execute_reply":"2024-04-22T23:55:59.030346Z"},"trusted":true},"execution_count":165,"outputs":[{"name":"stdout","text":"Overwriting app.py\n","output_type":"stream"}]},{"cell_type":"code","source":"# Your public ip is the password to the localtunnel\n!curl ipv4.icanhazip.com","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:55:59.282260Z","iopub.execute_input":"2024-04-22T23:55:59.282540Z","iopub.status.idle":"2024-04-22T23:56:00.248870Z","shell.execute_reply.started":"2024-04-22T23:55:59.282517Z","shell.execute_reply":"2024-04-22T23:56:00.247641Z"},"trusted":true},"execution_count":166,"outputs":[{"name":"stdout","text":"34.90.55.162\n","output_type":"stream"}]},{"cell_type":"code","source":"!streamlit run app.py &>./logs.txt & npx localtunnel --port 8501","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:56:00.250875Z","iopub.execute_input":"2024-04-22T23:56:00.251212Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"your url is: https://kind-cooks-fall.loca.lt\n","output_type":"stream"}]},{"cell_type":"code","source":"# Make image of rash for hand area fair skin eczema","metadata":{"execution":{"iopub.status.busy":"2024-04-22T23:48:08.341992Z","iopub.execute_input":"2024-04-22T23:48:08.342400Z","iopub.status.idle":"2024-04-22T23:48:08.348073Z","shell.execute_reply.started":"2024-04-22T23:48:08.342360Z","shell.execute_reply":"2024-04-22T23:48:08.347126Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"# for i in range(70):\n#     print(int((i+1)*100/70))","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:47:09.289198Z","iopub.execute_input":"2024-04-22T22:47:09.289603Z","iopub.status.idle":"2024-04-22T22:47:09.294860Z","shell.execute_reply.started":"2024-04-22T22:47:09.289563Z","shell.execute_reply":"2024-04-22T22:47:09.293619Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}